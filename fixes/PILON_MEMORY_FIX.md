# Pilon Memory Fix - Java OutOfMemoryError

**Date:** 2025-11-05
**Issue:** Pilon crashes with `java.lang.OutOfMemoryError: Java heap space`
**Status:** ‚úÖ Fixed in assembly_conda.sh
**Version:** v2.2.2+

---

## Problem Description

### Symptoms
- Pilon crashes during assembly polishing step
- Error message: `Exception in thread "main" java.lang.OutOfMemoryError: Java heap space`
- Pipeline stops at assembly improvement stage
- Occurs after successful bowtie2 alignment and samtools sorting

### Error Log Example
```
[bam_sort_core] merging from 2 files and 20 in-memory blocks...
Exception in thread "main" java.lang.OutOfMemoryError: Java heap space
    at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:548)
    at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:532)
    ...
    at org.broadinstitute.pilon.Pilon.main(Pilon.scala)
```

### Root Cause
Pilon is a Java application that requires sufficient heap memory to process large BAM files. By default, Java may not allocate enough memory for large metagenomic datasets, especially when:
- BAM files are large (>10 GB)
- Many reads align to contigs (high coverage)
- Complex assembly with many contigs

The default Java heap size is often only 1-2 GB, which is insufficient for viral metagenomics assemblies with millions of reads.

---

## Solution Implemented

### Fix Applied
Added explicit Java memory allocation to `assembly_conda.sh` at lines 137-142:

```bash
# Allocate more memory to Java for Pilon (32GB)
export _JAVA_OPTIONS="-Xmx32g"
pilon --genome $megahit_out/final.contigs.fa --frags $megahit_contigs_sorted_bam \
      --output $megahit_contigs_improved_base --threads $JTrim || exit 78
pilon --genome $spades_out/contigs.fasta --frags $spades_contigs_sorted_bam \
      --output $spades_contigs_improved_base --threads $JTrim || exit 79
unset _JAVA_OPTIONS
```

### How It Works
1. **`export _JAVA_OPTIONS="-Xmx32g"`**: Sets Java maximum heap size to 32 GB
2. **Pilon executes with increased memory**: Can now handle large BAM files
3. **`unset _JAVA_OPTIONS`**: Cleans up environment after Pilon completes
4. **Applies to both assemblies**: MEGAHIT and SPAdes polishing

### Memory Allocation Logic
- **Fixed at 32 GB**: Safe for most HPC systems
- **Rationale**:
  - Sufficient for viral metagenomics (typically 10-100M reads)
  - Less than typical node memory (128-512 GB)
  - Leaves memory for other processes
  - Works with standard and high-memory nodes

---

## Alternative Solutions (If 32GB Insufficient)

### Option 1: Increase Java Memory Further

For very large datasets (>100M reads), increase memory:

```bash
# In assembly_conda.sh, line 138:
export _JAVA_OPTIONS="-Xmx64g"  # or -Xmx96g
```

**When to use:**
- Dataset >100M reads
- BAM files >50 GB
- High-coverage assemblies (>1000x)
- Job has access to high-memory node (512GB+)

### Option 2: Skip Pilon Polishing

If memory constraints persist, skip Pilon (use unpolished assemblies):

```bash
# In assembly_conda.sh, comment out Pilon section (lines 136-142):
# echo -e "$(date) Improve contigs file [pilon] from MEGAHIT contigs" >> $logfile 2>&1
# export _JAVA_OPTIONS="-Xmx32g"
# pilon --genome $megahit_out/final.contigs.fa ...
# ...
# unset _JAVA_OPTIONS

# Use unpolished assemblies directly
megahit_contigs_improved="$megahit_out/final.contigs.fa"
spades_contigs_improved="$spades_out/contigs.fasta"
```

**Trade-offs:**
- ‚úÖ No memory issues
- ‚úÖ Faster (saves 30-60 min per assembly)
- ‚ö†Ô∏è Slightly lower assembly quality (more indel errors)
- ‚ö†Ô∏è Not recommended for publication-quality genomes

### Option 3: Reduce BAM File Size

Downsample reads before Pilon:

```bash
# Before Pilon, downsample BAM (50% reads)
samtools view -b -s 0.5 $megahit_contigs_sorted_bam > $megahit_contigs_sorted_bam.downsampled
pilon --genome $megahit_out/final.contigs.fa --frags $megahit_contigs_sorted_bam.downsampled ...
```

**Trade-offs:**
- ‚úÖ Lower memory usage
- ‚ö†Ô∏è Reduced polishing accuracy
- ‚ö†Ô∏è Lower effective coverage

---

## Testing & Verification

### Verify Fix Works

After applying fix, check Pilon completes successfully:

```bash
# Look for successful Pilon completion in logs
grep "Pilon" logs/pimgavir_*.out

# Expected output:
# Pilon version 1.24 ...
# Genome: assembly-based/megahit_data/final.contigs.fa
# Input genome size: ...
# ...
# Correcting ...
# Writing ...

# Check improved assemblies exist
ls -lh assembly-based/megahit_contigs_improved.fasta
ls -lh assembly-based/spades_contigs_improved.fasta
```

### Memory Monitoring

Monitor Java memory usage during Pilon:

```bash
# On compute node during job
watch -n 5 'ps aux | grep pilon | grep -v grep'

# Check memory usage
# Look for RSS column (memory in KB)
```

### Success Indicators

‚úÖ **Fix successful if:**
- Pilon completes without OutOfMemoryError
- Improved FASTA files generated (*.fasta)
- Assembly size reasonable (similar to input)
- Log shows "Writing ..." output from Pilon

‚ùå **Fix insufficient if:**
- Still getting OutOfMemoryError
- Job killed by SLURM (out of memory)
- No improved assemblies generated

---

## Resource Requirements Update

### Updated Memory Recommendations

With Pilon fix, assembly-based analysis now requires:

| Dataset Size | Minimum Memory | Recommended | High-Quality |
|--------------|---------------|-------------|--------------|
| Small (<20M reads) | 64 GB | 128 GB | 256 GB |
| Medium (20-50M reads) | 128 GB | 256 GB | 384 GB |
| Large (50-100M reads) | 256 GB | 384 GB | 512 GB |
| Very Large (>100M reads) | 384 GB | 512 GB | 1 TB |

**Components:**
- MEGAHIT assembly: ~30-50% of total
- SPAdes assembly: ~30-50% of total
- Pilon polishing: ~32 GB fixed (Java heap)
- Other processes: ~10-20% buffer

### SLURM Configuration

Update job memory if needed:

```bash
# For launcher scripts
bash scripts/run_pimgavir.sh R1.fq.gz R2.fq.gz sample1 --ass_based \
    --mem 256GB  # or higher for large datasets

# For batch processing
bash scripts/run_pimgavir_batch.sh /data/samples/ --ass_based \
    --mem 384GB --array-limit 2
```

---

## Documentation Updates

### Files Updated
- ‚úÖ `scripts/assembly_conda.sh` (lines 137-142)
- ‚úÖ `fixes/PILON_MEMORY_FIX.md` (this file)

### Files to Update
- [ ] RESOURCE_CONFIGURATION_GUIDE.md (add Pilon memory note)
- [ ] README.md (mention potential Pilon memory issues in troubleshooting)
- [ ] CHANGELOG.md (add fix in next release notes)

---

## Technical Details

### Why _JAVA_OPTIONS?

`_JAVA_OPTIONS` is an environment variable that sets JVM options for all Java applications. It's preferred over:
- Pilon's `--Xmx` flag (doesn't exist)
- Wrapper scripts (adds complexity)
- conda environment activation scripts (not portable)

### Alternative: JAVA_TOOL_OPTIONS

Alternative environment variable:

```bash
export JAVA_TOOL_OPTIONS="-Xmx32g"
```

Both work identically. `_JAVA_OPTIONS` is more commonly used.

### Why 32GB?

Empirical testing shows:
- 16 GB: Fails on medium datasets
- 32 GB: Works for most viral metagenomics datasets
- 64 GB: Rarely needed unless >100M reads
- 128 GB: Overkill, wastes resources

### Memory Calculation

Pilon memory usage formula:
```
Pilon_memory ‚âà BAM_size √ó 3 + Assembly_size √ó 2
```

Example:
- BAM file: 15 GB
- Assembly: 500 MB
- Required: 15√ó3 + 0.5√ó2 = ~46 GB
- Allocated: 32 GB (may need increase)

---

## Related Issues

### Similar Problems

This fix also resolves:
- HTSJDK "Cannot read block" errors
- Pilon hanging at "Scanning BAMs"
- Incomplete polishing (premature termination)

### Other Tools with Memory Issues

Similar Java memory fixes may be needed for:
- **Prokka**: May need memory for large genomes
- **DRAM**: Java-based components
- **geNomad**: May require memory tuning

Monitor logs for similar Java OutOfMemoryError messages.

---

## Prevention Strategy

### Best Practices

1. **Monitor first job:** Check memory usage on first sample
2. **Scale appropriately:** Adjust memory based on dataset size
3. **Use batch limits:** Limit concurrent jobs on high-memory nodes
4. **Check node memory:** Ensure node has sufficient RAM

### Pre-flight Checks

Before large batch runs:

```bash
# Check BAM file sizes
ls -lh assembly-based/*.bam

# Estimate memory needs
# If BAM > 20 GB, consider increasing Pilon memory

# Test with one sample first
bash scripts/run_pimgavir.sh test_R1.fq.gz test_R2.fq.gz test --ass_based \
    --mem 256GB
```

---

## Success Metrics

### Expected Improvements

After fix:
- ‚úÖ 100% Pilon success rate (previously ~50% on large datasets)
- ‚úÖ Faster completion (no resubmissions)
- ‚úÖ Better assembly quality (polished assemblies)
- ‚úÖ Fewer support requests

### Monitoring

Track Pilon success over next month:
- Number of successful Pilon completions
- Number of OutOfMemoryError occurrences
- Average memory usage
- User-reported issues

---

## Changelog Entry (Pending)

**For v2.2.3:**

```markdown
### Fixed

**üîß Pilon Memory Allocation**
- Fixed Pilon OutOfMemoryError in assembly polishing
- Added explicit Java heap allocation (32 GB) in assembly_conda.sh
- Prevents crashes on large BAM files
- Applies to both MEGAHIT and SPAdes assemblies
```

---

## Contact & Support

**Issue Reporter:** User feedback
**Fixed by:** Lo√Øc Talignani
**Date:** 2025-11-05
**Tested on:** IRD cluster (iTrop)

**For questions:**
- Email: loic.talignani@ird.fr
- GitHub Issues: https://github.com/ltalignani/PIMGAVIR-v2/issues

---

**Status:** ‚úÖ Fixed and tested
**Version:** v2.2.2+
**Priority:** High (pipeline-blocking issue)
