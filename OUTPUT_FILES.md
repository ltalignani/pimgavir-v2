# PIMGAVir Pipeline Output Files Documentation

**Version:** PIMGAVir V.2.1
**Last Updated:** October 29, 2025
**Purpose:** Complete reference of all files generated by the pipeline

---

## Table of Contents

1. [Directory Structure](#directory-structure)
2. [Pre-Processing Outputs](#1-pre-processing-outputs)
3. [Host/Contaminant Filtering](#2-optional-hostcontaminant-filtering)
4. [Read-Based Taxonomy](#3-read-based-taxonomy)
5. [Assembly-Based Taxonomy](#4-assembly-based-taxonomy)
6. [Clustering-Based Taxonomy](#5-clustering-based-taxonomy)
7. [Log Files and Reports](#6-log-files-and-reports)
8. [File Classification Summary](#file-classification-summary)
9. [Storage Recommendations](#storage-recommendations)
10. [Quick Reference Guide](#quick-reference-what-files-should-i-look-at)

---

## Directory Structure

```
/projects/large/PIMGAVIR/results/{JOBID}_{SAMPLENAME}_{METHOD}/scripts/
‚îú‚îÄ‚îÄ report/                                    # Log files and processing reports
‚îú‚îÄ‚îÄ read-based-taxonomy/                       # Direct read classification
‚îú‚îÄ‚îÄ assembly-based/                            # Assembly and classification
‚îÇ   ‚îú‚îÄ‚îÄ megahit_data/                         # MEGAHIT assembler output
‚îÇ   ‚îú‚îÄ‚îÄ megahit_quast/                        # MEGAHIT assembly QC
‚îÇ   ‚îú‚îÄ‚îÄ megahit_prokka/                       # MEGAHIT gene annotation
‚îÇ   ‚îú‚îÄ‚îÄ spades_data/                          # SPAdes assembler output
‚îÇ   ‚îú‚îÄ‚îÄ spades_quast/                         # SPAdes assembly QC
‚îÇ   ‚îú‚îÄ‚îÄ spades_prokka/                        # SPAdes gene annotation
‚îÇ   ‚îî‚îÄ‚îÄ IDXs/                                 # Bowtie2 index files
‚îú‚îÄ‚îÄ clustering-based/                          # OTU clustering and classification
‚îú‚îÄ‚îÄ {SAMPLENAME}_assembly-based-taxonomy/      # Taxonomy from assembled contigs
‚îú‚îÄ‚îÄ {SAMPLENAME}_assembly-based-MEGAHIT-KRONA-BLAST/
‚îú‚îÄ‚îÄ {SAMPLENAME}_assembly-based-SPADES-KRONA-BLAST/
‚îú‚îÄ‚îÄ {SAMPLENAME}_clustering-based/
‚îú‚îÄ‚îÄ {SAMPLENAME}_clustering-based-taxonomy/
‚îú‚îÄ‚îÄ {SAMPLENAME}_clustering-based-KRONA-BLAST/
‚îî‚îÄ‚îÄ {SAMPLENAME}_read-based-KRONA-BLAST/      # Only if --read_based method
```

---

## 1. Pre-Processing Outputs

**Script:** `pre-process_conda.sh`
**Location:** Root of results directory (`/scripts/`)

### 1.1 Quality Trimming (TrimGalore)

| File | Format | Tool | Purpose | Keep? |
|------|--------|------|---------|-------|
| `{SAMPLE}_R1_trimmed.fq.gz` | FASTQ.gz | TrimGalore | Quality-trimmed forward reads (Q30, min 80bp) | Intermediate |
| `{SAMPLE}_R2_trimmed.fq.gz` | FASTQ.gz | TrimGalore | Quality-trimmed reverse reads (Q30, min 80bp) | Intermediate |
| `*_trimming_report.txt` | Text | TrimGalore | **Trimming statistics and adapter removal summary** | **‚úì Keep** |
| `*_fastqc.html` | HTML | FastQC | **Quality control report (post-trimming)** | **‚úì Keep** |
| `*_fastqc.zip` | ZIP | FastQC | FastQC data files | Keep |

**Script Reference:** Lines 28-39
```bash
trim_galore -j 8 --length 80 --paired $R1 $R2 -q 30 --fastqc
```

**Parameters:**
- Quality threshold: Q30
- Minimum read length: 80 bp
- Adapter detection: Automatic
- Parallel processing: 8 cores

### 1.2 rRNA Removal (BBDuk)

| File | Format | Tool | Purpose | Keep? |
|------|--------|------|---------|-------|
| `{SAMPLE}_not_rRNA_1.fq` | FASTQ | BBDuk | Forward reads without rRNA | Intermediate |
| `{SAMPLE}_not_rRNA_2.fq` | FASTQ | BBDuk | Reverse reads without rRNA | Intermediate |
| `{SAMPLE}_not_rRNA.fq.gz` | FASTQ.gz | cat+gzip | **Concatenated non-rRNA reads for taxonomy** | **‚úì Keep** |
| `{SAMPLE}_rRNA_1.fq` | FASTQ | BBDuk | Filtered rRNA forward reads | Delete |
| `{SAMPLE}_rRNA_2.fq` | FASTQ | BBDuk | Filtered rRNA reverse reads | Delete |
| `{SAMPLE}_rrna_stats.txt` | Text | BBDuk | **rRNA removal statistics** | **‚úì Keep** |

**Script Reference:** Lines 57-80
```bash
bbduk.sh in=$trimmedR1 in2=$trimmedR2 \
    ref=$refSLR138,$refSSR138 \
    out=$NotrRNAReads1 out2=$NotrRNAReads2 \
    outm=$rRNAReads1 outm2=$rRNAReads2 \
    stats=$statsFile threads=$JTrim k=43
```

**Parameters:**
- Database: SILVA 138.1 LSU + SSU
- K-mer size: 43 (high precision)
- Output: Concatenated paired reads

**Why BBDuk?**
- 10-20 minutes faster than SortMeRNA
- Lower memory usage
- Better performance on large datasets

---

## 2. Optional: Host/Contaminant Filtering

**Scripts:** `reads-filtering.sh`, `Misaele_Filter_Param.sh`
**Location:** Root of results directory
**Activated with:** `--filter` flag

### 2.1 Diamond BLAST Filtering

| File | Format | Tool | Purpose | Keep? |
|------|--------|------|---------|-------|
| `blastx_diamond.m8` | TSV | Diamond | BLAST alignment results (all hits) | Intermediate |
| `blastx_diamond_NoDup.m8` | TSV | awk | Deduplicated BLAST hits (best hit per read) | Intermediate |
| `NoDup.taxonomy.krona.html` | HTML | Krona | **Interactive taxonomy (pre-filtering)** | **‚úì Keep** |
| `blastx_diamond_NoDup_withTaxa.m8` | TSV | Taxonkit | BLAST hits with full taxonomy lineage | Intermediate |
| `blastx_diamond_NoDup_wanted.m8` | TSV | grep | Read IDs passing filter | Intermediate |
| `blastx_diamond_NoDup_withTaxa_wanted.m8` | TSV | grep | Filtered hits with taxonomy | Intermediate |
| `WantedReads.taxonomy.krona.html` | HTML | Krona | **Interactive taxonomy (post-filtering)** | **‚úì Keep** |
| `readsNotrRNA_filtered.fq` | FASTQ | seqtk | **Final filtered reads (viral-enriched)** | **‚úì Keep** |

**Diamond BLAST Format (m8):**
```
qseqid staxids bitscore sseqid pident length mismatch gapopen qstart qend sstart send evalue
```

**Filtering Strategy:**
1. BLAST against RefSeq protein database
2. Remove reads matching unwanted organisms (hosts, contaminants)
3. Keep only viral-matching or unmatched reads

---

## 3. Read-Based Taxonomy

**Script:** `taxonomy_conda.sh`
**Location:** `read-based-taxonomy/` or `{SAMPLENAME}_read-based-taxonomy/`
**Method:** Direct classification of reads

### 3.1 Kraken2 Classification

| File | Format | Tool | Purpose | Keep? |
|------|--------|------|---------|-------|
| `krakViral.out_READ` | TSV | Kraken2 | Full classification output (all reads) | Intermediate |
| `krakViral_class.out_READ` | FASTQ | Kraken2 | Classified reads only | Intermediate |
| `krakViral_unclass.out_READ` | FASTQ | Kraken2 | Unclassified reads | Intermediate |
| `krakViral_report.out_READ` | Text | Kraken2 | **Classification report with taxonomy counts** | **‚úì Keep** |
| `krakViral.krona_READ` | TSV | awk | Kraken2 results in Krona format | Intermediate |
| `krakViral.krona_READ.html` | HTML | Krona | **üéØ Interactive taxonomy visualization** | **‚úì FINAL** |

**Kraken2 Report Format:**
```
Percentage  NumFragsClade  NumFragsTaxon  Rank  TaxID  ScientificName
```

**Script Reference:** Lines 28-47
```bash
kraken2 --db $KrakenViralDB $FilteredReads \
    --output $krakenViralOut \
    --classified-out $krakenViralClassified \
    --unclassified-out $krakenViralUnClassified \
    --report $krakenViralReport \
    --threads $JTrim
```

### 3.2 Kaiju Classification

| File | Format | Tool | Purpose | Keep? |
|------|--------|------|---------|-------|
| `reads_kaiju.out_READ` | TSV | Kaiju | Raw classification results | Intermediate |
| `reads_kaiju.krona_READ` | TSV | kaiju2krona | Kaiju results in Krona format | Intermediate |
| `reads_kaiju.krona_READ.html` | HTML | Krona | **üéØ Interactive taxonomy visualization** | **‚úì FINAL** |

**Kaiju Output Format:**
```
C/U  ReadID  TaxID  Length  Matches
```
- `C` = Classified
- `U` = Unclassified

**Script Reference:** Lines 49-66
```bash
kaiju -t $kaijuNodes -f $kaijuDB -i $FilteredReads -o $kaijuOut -z $JTrim
kaiju2krona -t $kaijuNodes -n $kaijuNames -i $kaijuOut -o $kronaOut
ktImportText -o $kronaHTMLout $kronaOut
```

### 3.3 BLAST Visualization (--read_based only)

**Script:** `krona-blast_conda.sh`
**Location:** `{SAMPLENAME}_read-based-KRONA-BLAST/`

| File | Format | Tool | Purpose | Keep? |
|------|--------|------|---------|-------|
| `readsToblastn.fasta` | FASTA | seqkit | Converted reads for BLAST | Intermediate |
| `{SAMPLE}_blastn.out` | TSV | BLAST | **BLAST alignment against viral RefSeq** | **‚úì Keep** |
| `{SAMPLE}_krona_tax.lst` | TSV | awk | Taxonomy IDs from BLAST | Intermediate |
| `{SAMPLE}_krona_out.html` | HTML | Krona | **üéØ Interactive BLAST taxonomy** | **‚úì FINAL** |
| `{SAMPLE}_krona_stdout` | Text | Krona | Standard output log | Log |
| `{SAMPLE}_krona_stderr` | Text | Krona | Error log | Log |

**BLAST Format (outfmt 6):**
```
qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore staxids sscinames
```

**Script Reference:** Lines 63-75
```bash
blastn -query $merged_seq -db $ref_viruses_rep_genomes -out $blast_out \
    -outfmt "6 qseqid sseqid pident length ... staxids sscinames" \
    -max_target_seqs 1 -num_threads $JTrim
```

---

## 4. Assembly-Based Taxonomy

**Script:** `assembly.sh` + `taxonomy_conda.sh`
**Location:** `assembly-based/` and `{SAMPLENAME}_assembly-based-taxonomy/`
**Method:** Assemble contigs ‚Üí classify contigs

### 4.1 MEGAHIT Assembly

**Location:** `assembly-based/megahit_data/`

| File | Format | Tool | Purpose | Keep? |
|------|--------|------|---------|-------|
| `final.contigs.fa` | FASTA | MEGAHIT | Assembled contigs | Intermediate |
| `intermediate_contigs/` | Directory | MEGAHIT | Intermediate assembly files | Delete |
| `options.json` | JSON | MEGAHIT | Assembly parameters used | Keep |
| `log` | Text | MEGAHIT | Assembly log | **‚úì Keep** |

**Script Reference:** Line 79
```bash
megahit -t $JTrim --read $merged_seq \
    --k-list 21,41,61,81,99 \
    --no-mercy --min-count 2 \
    --out-dir $megahit_out
```

**Parameters:**
- K-mer sizes: 21, 41, 61, 81, 99
- Minimum count: 2
- Mode: No mercy (more stringent)

### 4.2 SPAdes Assembly

**Location:** `assembly-based/spades_data/`

| File | Format | Tool | Purpose | Keep? |
|------|--------|------|---------|-------|
| `contigs.fasta` | FASTA | SPAdes | Assembled contigs | Intermediate |
| `scaffolds.fasta` | FASTA | SPAdes | Scaffolded contigs | Intermediate |
| `assembly_graph.fastg` | FASTG | SPAdes | Assembly graph | Keep |
| `spades.log` | Text | SPAdes | Assembly log | **‚úì Keep** |
| `K*/` | Directories | SPAdes | K-mer specific assemblies | Delete |

**Script Reference:** Lines 91-96
```bash
metaspades.py -t $JTrim -1 Forward.fq.gz -2 Reverse.fq.gz -o $spades_out
```

### 4.3 Assembly Polishing (Pilon)

**Location:** `assembly-based/`

| File | Format | Tool | Purpose | Keep? |
|------|--------|------|---------|-------|
| `IDXs/*_idx.*` | Binary | Bowtie2 | Bowtie2 index files | Intermediate |
| `megahit_contigs.bam` | BAM | Bowtie2 | Unsorted alignments (MEGAHIT) | Delete |
| `megahit_contigs.sorted.bam` | BAM | Samtools | Sorted alignments (MEGAHIT) | Intermediate |
| `megahit_contigs.sorted.bam.bai` | BAI | Samtools | BAM index (MEGAHIT) | Intermediate |
| `megahit_contigs_improved.fasta` | FASTA | Pilon | **üéØ Polished MEGAHIT contigs** | **‚úì FINAL** |
| `megahit_contigs_improved.changes` | Text | Pilon | **Corrections made by Pilon** | **‚úì Keep** |
| `spades_contigs.bam` | BAM | Bowtie2 | Unsorted alignments (SPAdes) | Delete |
| `spades_contigs.sorted.bam` | BAM | Samtools | Sorted alignments (SPAdes) | Intermediate |
| `spades_contigs.sorted.bam.bai` | BAI | Samtools | BAM index (SPAdes) | Intermediate |
| `spades_contigs_improved.fasta` | FASTA | Pilon | **üéØ Polished SPAdes contigs** | **‚úì FINAL** |
| `spades_contigs_improved.changes` | Text | Pilon | **Corrections made by Pilon** | **‚úì Keep** |

**Pilon Workflow:**
1. Build Bowtie2 index from contigs
2. Align reads to contigs
3. Sort and index BAM files
4. Pilon polishing to correct errors

**Script Reference:** Lines 102-143
```bash
# Index building
bowtie2-build $megahit_out/final.contigs.fa $idx_bowtie/$megahit_contigs_idx

# Read alignment
bowtie2 -x $idx_bowtie/$megahit_contigs_idx -1 Forward.fq.gz -2 Reverse.fq.gz | \
    samtools view -bS -o $megahit_contigs_bam

# Sorting and indexing
samtools sort $megahit_contigs_bam -o $megahit_contigs_sorted_bam
samtools index $megahit_contigs_sorted_bam

# Polishing
pilon --genome $megahit_out/final.contigs.fa \
    --frags $megahit_contigs_sorted_bam \
    --output $megahit_contigs_improved \
    --threads $JTrim
```

### 4.4 Assembly Quality Assessment (QUAST)

**Location:** `assembly-based/megahit_quast/` and `assembly-based/spades_quast/`

| File | Format | Tool | Purpose | Keep? |
|------|--------|------|---------|-------|
| `report.txt` | Text | QUAST | Assembly statistics summary | **‚úì Keep** |
| `report.html` | HTML | QUAST | **üéØ Interactive assembly statistics** | **‚úì FINAL** |
| `report.pdf` | PDF | QUAST | Assembly statistics report | **‚úì Keep** |
| `report.tsv` | TSV | QUAST | Machine-readable statistics | **‚úì Keep** |
| `basic_stats/` | Directory | QUAST | Basic statistics plots | Keep |
| `icarus.html` | HTML | QUAST | **Contig browser** | **‚úì Keep** |

**Key Metrics:**
- Number of contigs
- Largest contig
- Total length
- N50, N75, L50, L75
- GC content
- Number of N's per 100 kbp

**Script Reference:** Lines 156-157
```bash
quast.py -o $megahit_quast $megahit_contigs_improved".fasta"
quast.py -o $spades_quast $spades_contigs_improved".fasta"
```

### 4.5 Gene Annotation (PROKKA)

**Location:** `assembly-based/megahit_prokka/` and `assembly-based/spades_prokka/`

| File | Format | Tool | Purpose | Keep? |
|------|--------|------|---------|-------|
| `*.fna` | FASTA | PROKKA | Nucleotide sequences of genes | **‚úì Keep** |
| `*.faa` | FASTA | PROKKA | Protein sequences of genes | **‚úì Keep** |
| `*.gbk` | GenBank | PROKKA | **üéØ GenBank annotation (Artemis-compatible)** | **‚úì FINAL** |
| `*.gff` | GFF3 | PROKKA | **üéØ Gene feature annotations** | **‚úì FINAL** |
| `*.tsv` | TSV | PROKKA | **Gene summary table** | **‚úì Keep** |
| `*.txt` | Text | PROKKA | Annotation statistics | **‚úì Keep** |
| `*.log` | Text | PROKKA | Processing log | Log |
| `*.err` | Text | PROKKA | Error log | Log |

**PROKKA TSV Format:**
```
locus_tag  ftype  length_bp  gene  EC_number  COG  product
```

**Script Reference:** Lines 186-190
```bash
prokka $spades_contigs_improved".fasta" \
    --usegenus Viruses \
    --out $spades_prokka \
    --prefix spades_prokka \
    --cpus $JTrim
```

**Applications:**
- View in Artemis for genome browsing
- Import into Geneious for analysis
- Export gene sequences for further analysis

### 4.6 Assembly Taxonomy Classification

**Location:** `{SAMPLENAME}_assembly-based-taxonomy/`

Same file structure as [Read-Based Taxonomy](#3-read-based-taxonomy), but with `_MEGAHIT` or `_SPADES` suffixes:

- `krakViral.out_MEGAHIT` / `krakViral.out_SPADES`
- `krakViral_report.out_MEGAHIT` / `krakViral_report.out_SPADES` (**‚úì Keep**)
- `krakViral.krona_MEGAHIT.html` / `krakViral.krona_SPADES.html` (**‚úì FINAL**)
- `reads_kaiju.out_MEGAHIT` / `reads_kaiju.out_SPADES`
- `reads_kaiju.krona_MEGAHIT.html` / `reads_kaiju.krona_SPADES.html` (**‚úì FINAL**)

### 4.7 Assembly BLAST Visualization

**Location:** `{SAMPLENAME}_assembly-based-MEGAHIT-KRONA-BLAST/` and `{SAMPLENAME}_assembly-based-SPADES-KRONA-BLAST/`

Same file structure as [Read-Based BLAST](#33-blast-visualization---read_based-only).

---

## 5. Clustering-Based Taxonomy

**Script:** `clustering.sh` + `taxonomy_conda.sh`
**Location:** `clustering-based/` and `{SAMPLENAME}_clustering-based-taxonomy/`
**Method:** Cluster similar reads ‚Üí classify OTU representatives

### 5.1 VSEARCH Clustering Pipeline

**Location:** `clustering-based/{MERGED_SEQ}.split/`

| File | Format | Tool | Purpose | Keep? |
|------|--------|------|---------|-------|
| `Forward.fq.gz` | FASTQ.gz | seqkit | Split forward reads | Intermediate |
| `Reverse.fq.gz` | FASTQ.gz | seqkit | Split reverse reads | Intermediate |
| `Forward.fasta` | FASTA | seqkit | Converted forward reads | Intermediate |
| `Reverse.fasta` | FASTA | seqkit | Converted reverse reads | Intermediate |
| `Concatenated_Unmerged.fasta` | FASTA | Python | Paired reads concatenated with 10 N's | Intermediate |
| `Combined.fasta` | FASTA | cat | All sequences for dereplication | Delete |
| `derep.fasta` | FASTA | VSEARCH | Dereplicated sequences | Delete |
| `combined.uc` | UC | VSEARCH | Dereplication cluster map | Intermediate |
| `preclustered.fasta` | FASTA | VSEARCH | Pre-clustered (95% ID) | Delete |
| `nonchimeras.fasta` | FASTA | VSEARCH | Chimera-filtered sequences | Delete |
| `clustered.uc` | UC | VSEARCH | **Final cluster map** | **‚úì Keep** |
| `MSA.fa` | FASTA | VSEARCH | **Multiple sequence alignment** | **‚úì Keep** |

**VSEARCH Workflow:**
1. **Split**: Separate paired reads
2. **Convert**: FASTQ ‚Üí FASTA
3. **Concatenate**: Join pairs with 10 N's separator
4. **Dereplicate**: Remove exact duplicates
5. **Precluster**: Initial 95% identity clustering
6. **Denoise**: Remove chimeras
7. **Cluster**: Final 95% identity OTU clustering

**Script Reference:** Lines 36-109
```bash
# Split reads
seqkit split2 -p 2 $merged_seq -O $wd --force

# Convert to FASTA
for f in $wd/* ; do seqkit fq2fa $f -o ${f%.*}.fasta; done

# Concatenate pairs with Python script
python3 concatenate_reads.py

# Dereplication
vsearch --derep_fulllength Combined.fasta \
    --output derep.fasta --sizeout --uc combined.uc

# Pre-clustering
vsearch --cluster_size derep.fasta --id 0.95 \
    --sizein --sizeout --centroids preclustered.fasta

# Chimera filtering
vsearch --uchime_denovo preclustered.fasta \
    --sizein --sizeout --nonchimeras nonchimeras.fasta

# Final clustering
vsearch --cluster_size nonchimeras.fasta --id 0.95 \
    --sizein --sizeout --uc clustered.uc \
    --relabel OTU_ --centroids otus.fasta \
    --otutabout otutab.txt --biomout otu.biom \
    --msaout MSA.fa
```

### 5.2 OTU Output Files

**Location:** `clustering-based/`

| File | Format | Tool | Purpose | Keep? |
|------|--------|------|---------|-------|
| `otus.fasta` | FASTA | VSEARCH | **üéØ Representative OTU sequences** | **‚úì FINAL** |
| `otutab.txt` | TSV | VSEARCH | **üéØ OTU abundance table** | **‚úì FINAL** |
| `otu.biom` | BIOM | VSEARCH | **üéØ OTU table (BIOM format for QIIME2)** | **‚úì FINAL** |

**OTU Table Format (otutab.txt):**
```
#OTU ID  Sample1  Sample2  Sample3  ...
OTU_1    145      234      89
OTU_2    67       123      45
...
```

**BIOM Format:**
- Standard for microbiome analysis
- Compatible with QIIME2, phyloseq (R)
- Contains abundance + metadata

### 5.3 OTU Taxonomy Classification

**Location:** `{SAMPLENAME}_clustering-based-taxonomy/`

Same file structure as [Read-Based Taxonomy](#3-read-based-taxonomy), but with `_OTU` suffix:

- `krakViral.out_OTU`
- `krakViral_report.out_OTU` (**‚úì Keep**)
- `krakViral.krona_OTU.html` (**‚úì FINAL**)
- `reads_kaiju.out_OTU`
- `reads_kaiju.krona_OTU.html` (**‚úì FINAL**)

### 5.4 OTU BLAST Visualization

**Location:** `{SAMPLENAME}_clustering-based-KRONA-BLAST/`

Same file structure as [Read-Based BLAST](#33-blast-visualization---read_based-only).

---

## 6. Log Files and Reports

**Location:** `report/`

| File | Format | Purpose | Keep? |
|------|--------|---------|-------|
| `pre-process.log` | Text | Pre-processing log (TrimGalore + BBDuk) | **‚úì Keep** |
| `trim-galore.log` | Text | TrimGalore detailed output | **‚úì Keep** |
| `reads-filtering.log` | Text | Diamond BLAST filtering log | **‚úì Keep** |
| `Misaele_Filter_Param.log` | Text | Host filtering post-processing | **‚úì Keep** |
| `taxonomy.log` | Text | Kraken2/Kaiju classification logs | **‚úì Keep** |
| `assembly-based.log` | Text | Assembly pipeline log | **‚úì Keep** |
| `clustering-based.log` | Text | VSEARCH clustering log | **‚úì Keep** |
| `krona-blast.log` | Text | BLAST and Krona visualization logs | **‚úì Keep** |

**Log Format:**
```
[Date] Action description
Tool output...
[Date] Task completed
```

---

## File Classification Summary

### üéØ FINAL RESULTS (Primary Outputs - Must Keep)

#### Pre-processing
- `{SAMPLE}_not_rRNA.fq.gz` - Filtered reads
- `*_trimming_report.txt` - QC statistics
- `*.html` - FastQC reports
- `{SAMPLE}_rrna_stats.txt` - rRNA removal stats

#### Filtering (if --filter)
- `readsNotrRNA_filtered.fq` - Viral-enriched reads
- `NoDup.taxonomy.krona.html` - Pre-filtering taxonomy
- `WantedReads.taxonomy.krona.html` - Post-filtering taxonomy

#### Read-Based Taxonomy
- `krakViral_report.out_READ` - Kraken2 report
- `krakViral.krona_READ.html` - Kraken2 visualization
- `reads_kaiju.krona_READ.html` - Kaiju visualization
- `{SAMPLE}_blastn.out` - BLAST results
- `{SAMPLE}_krona_out.html` - BLAST visualization

#### Assembly-Based
- `megahit_contigs_improved.fasta` - Polished MEGAHIT contigs
- `spades_contigs_improved.fasta` - Polished SPAdes contigs
- `megahit_quast/report.html` - MEGAHIT QC
- `spades_quast/report.html` - SPAdes QC
- `megahit_prokka/*.gbk` - MEGAHIT annotation
- `spades_prokka/*.gbk` - SPAdes annotation
- `krakViral.krona_MEGAHIT.html` / `_SPADES.html` - Taxonomy
- Assembly BLAST visualizations

#### Clustering-Based
- `otus.fasta` - OTU sequences
- `otutab.txt` - OTU abundance table
- `otu.biom` - BIOM format
- `krakViral.krona_OTU.html` - OTU taxonomy
- OTU BLAST visualizations

#### Logs
- All files in `report/` directory

### üì¶ INTERMEDIATE FILES (Can delete after verification)

- `*_trimmed.fq.gz` - Trimmed reads (pre-rRNA removal)
- `*_not_rRNA_1.fq`, `*_not_rRNA_2.fq` - Unpaired non-rRNA reads
- `blastx_diamond*.m8` - Diamond filtering intermediates
- `*.bam`, `*.bai` - Alignment files
- `derep.fasta`, `preclustered.fasta`, `nonchimeras.fasta` - Clustering intermediates
- Kraken2/Kaiju `.out` files (keep only reports and HTML)

### üóëÔ∏è DELETABLE FILES (Temporary/unnecessary)

- `*_rRNA_*.fq` - Filtered rRNA reads
- `Combined.fasta` - Pre-dereplication combined file
- Bowtie2 index files (`IDXs/`)
- MEGAHIT/SPAdes intermediate directories (`K*/`, `intermediate_contigs/`)
- Input FASTQ files copied to scratch

---

## Storage Recommendations

### üíæ Minimal Storage (Essential Results Only)
**Keep:**
1. HTML Krona visualizations
2. Polished assembly FASTA files
3. PROKKA GenBank files (`.gbk`, `.gff`)
4. OTU tables and sequences
5. Log files in `report/`

**Estimated Size:** ~500 MB - 2 GB per sample

### üíø Standard Storage (Recommended)
**Keep:**
1. All FINAL RESULTS (see summary above)
2. Filtered reads (`*_not_rRNA.fq.gz`, `readsNotrRNA_filtered.fq`)
3. Classification reports (Kraken2/Kaiju)
4. All logs

**Estimated Size:** ~2 GB - 10 GB per sample

### üíΩ Full Storage (Complete Pipeline Outputs)
Keep everything including intermediate files for reproducibility.

**Estimated Size:** ~10 GB - 50 GB per sample (depending on input size)

---

## File Format Reference

| Format | Description | Viewers/Tools |
|--------|-------------|---------------|
| **FASTQ** | Raw sequence data + quality scores | FastQC, SeqKit |
| **FASTA** | Sequence data without quality | Any text editor, SeqKit |
| **TSV/M8** | Tab-separated values (BLAST format 6) | Excel, R, Python |
| **HTML** | Interactive web visualizations | Any web browser |
| **BAM/BAI** | Binary alignment format | IGV, samtools |
| **GenBank (.gbk)** | Annotated genome format | Artemis, Geneious |
| **GFF3** | Gene feature format | IGV, Artemis |
| **BIOM** | Biological observation matrix | QIIME2, phyloseq (R) |
| **UC** | VSEARCH cluster format | Text editor, custom parsers |
| **JSON** | Structured data format | Text editor, jq |

---

## Quick Reference: What Files Should I Look At?

### "What viruses were found?"

**Read-based:**
- `read-based-taxonomy/krakViral.krona_READ.html`
- `read-based-taxonomy/reads_kaiju.krona_READ.html`
- `{SAMPLE}_read-based-KRONA-BLAST/{SAMPLE}_krona_out.html`

**Assembly-based:**
- `{SAMPLE}_assembly-based-taxonomy/krakViral.krona_MEGAHIT.html`
- `{SAMPLE}_assembly-based-taxonomy/krakViral.krona_SPADES.html`
- `{SAMPLE}_assembly-based-MEGAHIT-KRONA-BLAST/{SAMPLE}_krona_out.html`
- `{SAMPLE}_assembly-based-SPADES-KRONA-BLAST/{SAMPLE}_krona_out.html`

**Clustering-based:**
- `{SAMPLE}_clustering-based-taxonomy/krakViral.krona_OTU.html`
- `{SAMPLE}_clustering-based-KRONA-BLAST/{SAMPLE}_krona_out.html`

### "How good was my sequencing data?"

- `*_fastqc.html` - FastQC quality reports
- `*_trimming_report.txt` - Trimming statistics
- `{SAMPLE}_rrna_stats.txt` - rRNA removal statistics

### "How good was the assembly?"

- `assembly-based/megahit_quast/report.html` - MEGAHIT assembly QC
- `assembly-based/spades_quast/report.html` - SPAdes assembly QC
- `report/assembly-based.log` - Assembly pipeline log

### "What genes were found?"

- `assembly-based/megahit_prokka/megahit_prokka.gbk` - MEGAHIT annotation (Artemis)
- `assembly-based/spades_prokka/spades_prokka.gbk` - SPAdes annotation (Artemis)
- `*_prokka/*.tsv` - Gene summary tables
- `*_prokka/*.faa` - Protein sequences

### "What are the OTU clusters?"

- `clustering-based/otus.fasta` - Representative OTU sequences
- `clustering-based/otutab.txt` - OTU abundance table
- `clustering-based/otu.biom` - BIOM format (QIIME2/phyloseq)
- `clustering-based/MSA.fa` - Multiple sequence alignment

### "What happened during processing?"

- `report/*.log` - All processing logs
- `pimgavir.log` - Main pipeline log (in worker root)
- SLURM logs: `/projects/large/PIMGAVIR/pimgavir_dev/logs/pimgavir_*.out/err`

---

## Tool Output Formats

### Kraken2 Output
```
C/U  ReadID  TaxID  Length  LCA_mapping
```

### Kaiju Output
```
C/U  ReadID  TaxID  Length  Matches
```

### BLAST Format 6 (outfmt 6)
```
qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore staxids sscinames
```

### VSEARCH UC Format
```
Type  Cluster  Size  %ID  Strand  _  _  Alignment  Query  Target
```

### QUAST Key Metrics
- **# contigs**: Total number of contigs
- **Largest contig**: Size of the largest contig (bp)
- **Total length**: Sum of all contig lengths (bp)
- **N50**: 50% of assembly is in contigs ‚â• this size
- **L50**: Minimum number of contigs containing 50% of assembly
- **GC (%)**: GC content percentage

---

## Notes

### Parallel Execution (ALL mode)
When running with `METHOD=ALL`, threads are divided by 3 and all three methods run in parallel. Check for `_READ`, `_MEGAHIT`, `_SPADES`, and `_OTU` suffixes to distinguish outputs.

### Array Jobs
When using the batch launcher, each sample gets: `{SLURM_ARRAY_JOB_ID}_{SAMPLE}_{METHOD}`

### Scratch vs Permanent Storage
- Processing: `/scratch/` or `/scratch-ib/` (Infiniband)
- Results: `/projects/large/PIMGAVIR/results/`
- Scratch automatically cleaned after transfer

### Database Requirements
The pipeline requires databases in `DBs/` directory:
- SILVA rRNA references (138.1 LSU + SSU)
- Kraken2 viral database
- Kaiju viral database
- Diamond RefSeq protein database
- NCBI viral RefSeq for BLAST

### File Compression
Most sequence files are gzipped (`.gz`). Use `zcat` or `gunzip` to decompress.

---

## Troubleshooting

### Missing Expected Files?

**Check:**
1. SLURM logs for errors: `logs/pimgavir_*.err`
2. Pipeline logs: `report/*.log`
3. Method used: Files vary by `--read_based`, `--ass_based`, `--clust_based`, or `ALL`
4. Filter flag: `--filter` creates additional files

### Files Too Large?

**Consider:**
1. Compress with gzip: `gzip *.fasta`
2. Remove intermediate files (see classification summary)
3. Keep only FINAL results

### Cannot Open HTML Files?

**Solution:**
- Transfer to local machine: `scp cluster:/path/to/file.html ./`
- Open in web browser (Chrome, Firefox, Safari)

---

## Version Information

- **Pipeline Version:** PIMGAVir V.2.1
- **Documentation Date:** October 29, 2025
- **Scripts Analyzed:**
  - `pre-process_conda.sh`
  - `taxonomy_conda.sh`
  - `krona-blast_conda.sh`
  - `assembly.sh`
  - `clustering.sh`
  - `reads-filtering.sh`
  - `Misaele_Filter_Param.sh`

---

## üÜï Viral Genome Analysis Outputs (7 Phases) - NEW in v2.2

When using `--ass_based` or `ALL`, the pipeline automatically runs comprehensive viral genome analysis. Output location:

```
assembly-based/
‚îú‚îÄ‚îÄ viral-genomes-megahit/     # MEGAHIT viral analysis
‚îî‚îÄ‚îÄ viral-genomes-spades/      # SPAdes viral analysis
```

### Phase 6: Zoonotic Risk Assessment

**Location:** `phase6_zoonotic/`

#### Furin Cleavage Sites
**Directory:** `furin_sites/`
- `{SAMPLE}_furin_sites.txt` - All detected furin sites with patterns and positions ‚ö†Ô∏è
- `{SAMPLE}_furin_containing_proteins.faa` - Protein sequences with furin sites
- **Purpose:** Identify proteins with furin cleavage recognition sequences
- **Format:** TSV (Protein_ID, Type, Pattern, Position, Score, Context)
- **Keep?** ‚úÖ YES - Critical for zoonotic assessment

#### RBD Analysis
**Directory:** `rbd_analysis/`
- `{SAMPLE}_spike_proteins.txt` - Identified surface/spike proteins
- `{SAMPLE}_rbd_candidates.faa` - Potential receptor binding domain sequences ‚ö†Ô∏è
- **Purpose:** Identify proteins that may bind host receptors
- **Format:** TSV (Protein_ID, Length, Features) and FASTA
- **Keep?** ‚úÖ YES - Important for host tropism analysis

#### Zoonotic Similarity
**Directory:** `zoonotic_similarity/` (if zoonotic DB provided)
- `{SAMPLE}_vs_zoonotic.blastp` - BLAST results vs known zoonotic viruses
- `{SAMPLE}_zoonotic_similarity.txt` - High-similarity matches summary
- **Purpose:** Compare with known zoonotic pathogens
- **Format:** BLAST tabular format
- **Keep?** ‚úÖ YES if high similarity found

#### Receptor Analysis
**Directory:** `receptor_analysis/`
- `{SAMPLE}_rbd_patterns.txt` - RBD feature analysis
- **Purpose:** Detailed RBD characteristics
- **Format:** TSV
- **Keep?** üü° OPTIONAL - Detailed analysis data

#### Final Reports
**Directory:** `results/`
- `{SAMPLE}_zoonotic_risk_report.txt` - **MASTER REPORT** ‚≠ê‚ö†Ô∏è
  - Complete risk assessment
  - Zoonotic risk score (0-100)
  - Alert level (HIGH/MEDIUM/LOW)
  - Interpretation and recommendations
  - **Keep?** ‚úÖ YES - CRITICAL DOCUMENT

- `{SAMPLE}_zoonotic_summary.tsv` - Per-genome risk scores
  - **Keep?** ‚úÖ YES - For publication

**Storage:** ~50-200 MB depending on genome count

**Important:** üî¥ ALL HIGH RISK findings (score ‚â•70) must be:
- Reported to institutional biosafety committee
- Reported to public health authorities (if appropriate)
- Handled with BSL-3 or higher containment

---

### Phase 7: Publication Report Generation

**Location:** `phase7_publication_report/`

#### Figures (Publication-Ready)
**Directory:** `figures/`
- `Figure2_AMG_Heatmap.pdf` - Auxiliary metabolic genes heatmap üìä
- `Figure2_AMG_Heatmap.png` - High-res version (300 DPI)
- `Figure3_Phylogenetic_Tree.pdf` - ML phylogenetic tree üå≥
- `Figure3_Phylogenetic_Tree.png` - High-res version
- `Figure3_Tree_File.nwk` - Newick format for FigTree/iTOL
- `Figure4_Diversity.pdf` - Viral diversity plots (4-panel) üìà
- `Figure4_Diversity.png` - High-res version
- `*.R` - R scripts for figure customization
- `*.py` - Python scripts for figure customization

**Format:** PDF (vector) + PNG (raster, 300 DPI)
**Purpose:** Ready for manuscript submission
**Keep?** ‚úÖ YES - Customize and submit with paper

#### Tables (Supplementary Data)
**Directory:** `tables/`
- `TableS1_Viral_Genomes.tsv` - High-quality viral genomes with metrics üìã
- `TableS2_AMG_Predictions.tsv` - AMG predictions with confidence
- `TableS3_Host_Predictions.tsv` - Host predictions with evidence
- `TableS4_Zoonotic_Risk.tsv` - Zoonotic risk assessment per genome

**Format:** TSV (tab-separated values, Excel-compatible)
**Purpose:** Supplementary materials for manuscript
**Keep?** ‚úÖ YES - Format for journal requirements

#### Methods Section
**Directory:** `methods/`
- `methods_section.txt` - **Complete methods text** ‚≠ê
  - Ready-to-use for manuscript
  - All software versions and citations
  - Database versions
  - Parameter settings
  - Statistical analysis templates
  - Data availability statement template

**Format:** Plain text (Markdown-style)
**Purpose:** Copy directly into manuscript
**Keep?** ‚úÖ YES - Adapt to your specific study

#### Interactive HTML Report
**Directory:** `html_report/`
- `interactive_report.html` - **Complete analysis dashboard** üåê ‚≠ê
  - Executive summary with key metrics
  - Phase-by-phase results
  - Links to all output files
  - Publication materials checklist
  - Modern responsive design
  - Shareable with collaborators

**Format:** Self-contained HTML (open in any browser)
**Purpose:** Review all results in one place
**Keep?** ‚úÖ YES - Share with team, use for presentations

#### Summary
**Directory:** `phase7_publication_report/` (root)
- `{SAMPLE}_publication_report_summary.txt` - Quick reference guide

**Storage:** ~10-100 MB (depends on figure/table sizes)

---

### Master Summary Report

**Location:** `{output_dir}/` (root)
- `{SAMPLE}_complete_analysis.log` - Complete log of all 7 phases
- `final_results/` - Key files from all phases copied here

**final_results/ Contents:**
- `{SAMPLE}_hq_viruses.fasta` - High-quality viral genomes (Phase 1)
- `amg_summary.tsv` - AMG predictions (Phase 2)
- `{SAMPLE}_viral.treefile` - Phylogenetic tree (Phase 3)
- `genome_by_genome_overview.csv` - Taxonomy (Phase 4)
- `{SAMPLE}_host_predictions.tsv` - Host predictions (Phase 5)
- `{SAMPLE}_zoonotic_risk_report.txt` - Risk assessment (Phase 6) ‚ö†Ô∏è
- `interactive_report.html` - HTML report (Phase 7) üåê

**Purpose:** Easy access to most important files
**Keep?** ‚úÖ YES - These are your key results

---

### Quick Reference: Viral Analysis Outputs

#### üî¥ CRITICAL - Must Review
- `phase6_zoonotic/results/{SAMPLE}_zoonotic_risk_report.txt` - Check risk score!
- `phase7_publication_report/html_report/interactive_report.html` - Review all results
- `final_results/` directory - All key outputs

#### ‚≠ê HIGH PRIORITY - For Publication
- `phase7_publication_report/figures/` - Publication figures
- `phase7_publication_report/tables/` - Supplementary tables
- `phase7_publication_report/methods/methods_section.txt` - Methods text
- `phase1_recovery/high_quality_viruses/` - Your viral genomes
- `phase2_annotation/dramv/distill/amg_summary.tsv` - AMG findings

#### üü° MEDIUM PRIORITY - For Detailed Analysis
- `phase3_phylogenetics/` - Phylogenetic trees and alignments
- `phase4_comparative/vcontact2/` - Taxonomy networks
- `phase5_host_ecology/results/` - Host predictions
- `phase6_zoonotic/furin_sites/` - If furin sites detected
- `phase6_zoonotic/rbd_analysis/` - If RBDs identified

#### üü¢ LOW PRIORITY - Can Delete After Review
- Intermediate files in each phase directory
- Log files (after confirming success)
- Temporary alignment files
- Intermediate BLAST results

#### ‚ö†Ô∏è SAFETY WARNING
If Phase 6 reports HIGH RISK (score ‚â•70):
1. **Stop and review immediately**
2. Report to institutional biosafety committee
3. Report to public health authorities (if appropriate)
4. Secure samples (BSL-3 or higher)
5. Do NOT proceed with experimental work without approval

---

### Storage Recommendations: Viral Analysis

**Essential (keep forever):**
- `final_results/` - ~100-500 MB
- `phase7_publication_report/` - ~10-100 MB
- `phase6_zoonotic/results/` - ~10-50 MB
- `phase1_recovery/high_quality_viruses/` - ~10-100 MB
- **Total:** ~200 MB - 1 GB per sample

**Important (keep until published):**
- All phase directories with results/ subdirectories
- **Total:** Additional 2-5 GB per sample

**Optional (can delete after review):**
- Intermediate files and logs
- Can free up: 5-10 GB per sample

---

## Related Documentation

- **CLAUDE.md** - Pipeline architecture and usage
- **README.md** - Quick start guide
- **BATCH_PROCESSING_GUIDE.md** - Batch processing documentation
- **CONDA_MIGRATION_GUIDE.md** - Conda environment setup

---

**For questions or issues, refer to the main pipeline documentation or contact the maintainer.**
